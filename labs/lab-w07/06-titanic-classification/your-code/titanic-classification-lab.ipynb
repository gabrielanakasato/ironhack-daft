{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the processed titanic dataframe.\n",
    "\n",
    "Store it in a dataframe called `titanic_train` and `titanic_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T20:48:48.812051Z",
     "start_time": "2020-10-01T20:48:48.010211Z"
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "# Import libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T20:48:48.828980Z",
     "start_time": "2020-10-01T20:48:48.812989Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7417</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38.5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>19.2583</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24.1500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass   Age  SibSp  Parch     Fare  Sex_male  Embarked_Q  Embarked_S  \\\n",
       "0       3  25.0      0      0   7.7417         1           1           0   \n",
       "1       1  47.0      0      0  38.5000         1           0           1   \n",
       "2       3  24.0      0      3  19.2583         0           0           0   \n",
       "3       3  32.0      0      0   8.0500         1           0           1   \n",
       "4       3  39.0      0      0  24.1500         1           0           1   \n",
       "\n",
       "   Survived  \n",
       "0         0  \n",
       "1         0  \n",
       "2         1  \n",
       "3         1  \n",
       "4         0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the datasets\n",
    "titanic_train = pd.read_csv('../data/titanic_train.csv')\n",
    "titanic_test = pd.read_csv('../data/titanic_test.csv')\n",
    "\n",
    "# Check the results\n",
    "titanic_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T20:48:48.841949Z",
     "start_time": "2020-10-01T20:48:48.829944Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>69.3000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>78.2667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79.6500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>262.3750</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass   Age  SibSp  Parch      Fare  Sex_male  Embarked_Q  Embarked_S  \\\n",
       "0       1  24.0      0      0   69.3000         0           0           0   \n",
       "1       1  54.0      1      0   78.2667         0           0           0   \n",
       "2       1  52.0      1      1   79.6500         1           0           1   \n",
       "3       1  18.0      2      2  262.3750         0           0           0   \n",
       "4       2  27.0      0      0   26.0000         1           0           1   \n",
       "\n",
       "   Survived  \n",
       "0         1  \n",
       "1         1  \n",
       "2         0  \n",
       "3         1  \n",
       "4         0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Test\n",
    "\n",
    "You have separated the original dataset into train and test. In fact, what you were effectively doing was hiding some part of your data to analyse your scores afterwards."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Step: start simple\n",
    "\n",
    "You will select two variables to create the predictive variables for your problem - store the features representing the `Sex` and `Age` in dataframes called `X_train` and `X_test`. (maybe the `sex` variable is written as `Sex_male` for example, if you dummyfied it)\n",
    "\n",
    "Also store the variable `Survived` into pandas series called `y_train` and `y_test`. This is your target variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T20:48:48.847896Z",
     "start_time": "2020-10-01T20:48:48.842909Z"
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "# Create the variables\n",
    "X_train = titanic_train[['Sex_male', 'Age']]\n",
    "y_train = titanic_train['Survived']\n",
    "\n",
    "X_test = titanic_test[['Sex_male', 'Age']]\n",
    "y_test = titanic_test['Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression for classification\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the LogisticRegression classifier to train your model on your train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T20:48:49.128202Z",
     "start_time": "2020-10-01T20:48:48.849892Z"
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "# Import\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T20:48:49.142143Z",
     "start_time": "2020-10-01T20:48:49.129175Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instance the model\n",
    "logistic = LogisticRegression()\n",
    "\n",
    "# Train the model\n",
    "logistic.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use your logistic regression model to generate a prediction for your test dataset. \n",
    "\n",
    "Create a variable called `y_pred` to put the results of the model. Try to understand what exactly the `.predict()` method is doing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T20:48:49.157102Z",
     "start_time": "2020-10-01T20:48:49.144105Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 1),\n",
       " (1, 1),\n",
       " (0, 0),\n",
       " (1, 1),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (0, 0),\n",
       " (1, 1),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 1),\n",
       " (0, 0),\n",
       " (1, 1),\n",
       " (1, 0),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (0, 0),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 1),\n",
       " (0, 0),\n",
       " (1, 1),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (1, 1),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 1),\n",
       " (1, 1),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (0, 1),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (0, 1),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 1),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 1),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 1),\n",
       " (0, 0),\n",
       " (1, 1),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 1),\n",
       " (1, 0),\n",
       " (1, 1),\n",
       " (1, 0),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (1, 1),\n",
       " (0, 0),\n",
       " (1, 1),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 1),\n",
       " (0, 0),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (0, 0),\n",
       " (1, 1),\n",
       " (0, 1),\n",
       " (1, 1),\n",
       " (0, 0),\n",
       " (1, 1),\n",
       " (0, 0),\n",
       " (0, 1),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (1, 1),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 1),\n",
       " (0, 1),\n",
       " (1, 0),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (0, 1),\n",
       " (1, 1),\n",
       " (1, 0),\n",
       " (1, 1),\n",
       " (0, 0),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (0, 1),\n",
       " (1, 1),\n",
       " (0, 0),\n",
       " (1, 1),\n",
       " (1, 0),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (1, 1),\n",
       " (0, 0),\n",
       " (1, 1),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 1),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 1),\n",
       " (1, 0),\n",
       " (1, 1),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (1, 1),\n",
       " (0, 1),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (0, 1),\n",
       " (0, 1),\n",
       " (0, 1),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (0, 0),\n",
       " (0, 0)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "# Generate a prediction\n",
    "y_pred = logistic.predict(X_test)\n",
    "\n",
    "# Compare the 'y_pred' and 'y_test'\n",
    "list(zip(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the results\n",
    "\n",
    "Use your model's method called `score` to evaluate the results on your test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T20:48:49.166045Z",
     "start_time": "2020-10-01T20:48:49.158100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7471910112359551"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "# Evaluate the model's accuracy\n",
    "logistic.score(X=X_test, y=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To think:\n",
    "\n",
    "- What does the `.score()` method calculates?\n",
    "- Is this metric appropriate for this use case? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T20:48:49.177015Z",
     "start_time": "2020-10-01T20:48:49.169052Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The method score calculates the mean accuracy of the model, which means the percentage of correct predictions from all the\n",
      "predictions. In other words is how many correct predictions the model made from all the predictions. This model had a mean of\n",
      "74.72% of accuracy.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# your answer here\n",
    "\n",
    "print(f'''\n",
    "The method score calculates the mean accuracy of the model, which means the percentage of correct predictions from all the\n",
    "predictions. In other words is how many correct predictions the model made from all the predictions. This model had a mean of\n",
    "{logistic.score(X=X_test, y=y_test) * 100:.2f}% of accuracy.\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T20:48:49.192010Z",
     "start_time": "2020-10-01T20:48:49.178029Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERCENTAGE OF SURVIVAL\n",
      "Train\n",
      "0    60.861423\n",
      "1    39.138577\n",
      "Name: Survived, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Percentge of Survival\n",
    "print('PERCENTAGE OF SURVIVAL')\n",
    "print(f'Train\\n{titanic_train.Survived.value_counts(normalize=True) * 100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T20:48:49.195990Z",
     "start_time": "2020-10-01T20:48:49.192973Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Since this dataset is not very balanced, the accuracy is not the best method to evaluate the model.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('''\n",
    "Since this dataset is not very balanced, the accuracy is not the best method to evaluate the model.\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix\n",
    "\n",
    "Print the confusion matrix for the results obtained.\n",
    "\n",
    "_hint: You can use the `pd.crosstab()` or the_ `sklearn.metrics.confusion_matrix` _method_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T20:52:42.518271Z",
     "start_time": "2020-10-01T20:52:42.516269Z"
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "# Import\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T20:54:35.033163Z",
     "start_time": "2020-10-01T20:54:35.028176Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[82, 17],\n",
       "       [28, 51]], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "confusion_matrix(y_true=y_test, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T20:54:36.648789Z",
     "start_time": "2020-10-01T20:54:36.643778Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[46.06741573,  9.5505618 ],\n",
       "       [15.73033708, 28.65168539]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion matrix - percentage\n",
    "confusion_matrix(y_true=y_test, y_pred=y_pred, normalize='all') * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision-recall scores\n",
    "\n",
    "## Calculate the precision and recall scores for the test set. \n",
    "\n",
    "_hint: Use the methods from sklearn.metrics_ \n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T20:55:16.734984Z",
     "start_time": "2020-10-01T20:55:16.731993Z"
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "# Import\n",
    "from sklearn.metrics import precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T20:57:51.797026Z",
     "start_time": "2020-10-01T20:57:51.790045Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.75\n",
      "Recall: 0.6455696202531646\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "print(f'Precision: {precision_score(y_true=y_test, y_pred=y_pred)}')\n",
    "print(f'Recall: {recall_score(y_true=y_test, y_pred=y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions:\n",
    "\n",
    "- What do these precision and recall scores mean? Explain precision and recall with your own words.\n",
    "- Are these the precision and recall scores for which threshold? Explain what a threshold mean with your own words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T21:26:18.385827Z",
     "start_time": "2020-10-01T21:26:18.379838Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRECISION\n",
      "Precision is how many true positives the model predicted from all the positives predicted (true positives + false positives).\n",
      "The model got correctly 75.00% of the predicted positives.\n",
      "\n",
      "RECALL\n",
      "Recall is how many positives the model predicted from all the real positives (true positives + false negatives).\n",
      "The model got 64.56% of the real positives.\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "print(f'''PRECISION\n",
    "Precision is how many true positives the model predicted from all the positives predicted (true positives + false positives).\n",
    "The model got correctly {precision_score(y_true=y_test, y_pred=y_pred) * 100:.2f}% of the predicted positives.\n",
    "\n",
    "RECALL\n",
    "Recall is how many positives the model predicted from all the real positives (true positives + false negatives).\n",
    "The model got {recall_score(y_true=y_test, y_pred=y_pred) * 100:.2f}% of the real positives.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('''It is extremely important to remember that the values of these metrics are for the thershold equal to 0.5, meaning\n",
    "that, when the probability of being 1 is higher than 50%, the model classifies the element as 1. So, the threshold is similar\n",
    "to a limit of acceptance for an element being 1. \n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare a measure of accuracy, recall and precision for both train and test sets. \n",
    "\n",
    "You've calculated the metrics for the test dataset. Now, calculate the metrics for the train dataset and compare the results. What do you observe? Based on what you see, do you think your model has overfitted? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T21:44:19.756122Z",
     "start_time": "2020-10-01T21:44:19.741162Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST\n",
      "Precision: 0.75\n",
      "Recall: 0.6455696202531646\n",
      "\n",
      "TRAIN\n",
      "Precision: 0.7539267015706806\n",
      "Recall: 0.6889952153110048\n"
     ]
    }
   ],
   "source": [
    "# Evaluation - Test\n",
    "print('TEST')\n",
    "print(f'Precision: {precision_score(y_true=y_test, y_pred=y_pred)}')\n",
    "print(f'Recall: {recall_score(y_true=y_test, y_pred=y_pred)}')\n",
    "\n",
    "# Evaluation - Train\n",
    "print('\\nTRAIN')\n",
    "print(f'Precision: {precision_score(y_true=y_train, y_pred=logistic.predict(X_train))}')\n",
    "print(f'Recall: {recall_score(y_true=y_train, y_pred=logistic.predict(X_train))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T21:49:28.761015Z",
     "start_time": "2020-10-01T21:49:28.756013Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Since the metrics for the test set are similar to the train one, the model did not overfitted.\n"
     ]
    }
   ],
   "source": [
    "print('Since the metrics for the test set are similar to the train one, the model did not overfitted.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-linear Models - Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a decision tree model using the default arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T02:02:28.442385Z",
     "start_time": "2020-04-27T02:02:28.439417Z"
    }
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T02:03:24.831857Z",
     "start_time": "2020-04-27T02:03:24.829850Z"
    }
   },
   "source": [
    "## Calculate the accuracy, precision and recall scores for both the `training set` and the `test set`.\n",
    "\n",
    "After calculating it, compare the results. What do you observe? Do you understand what does that mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting trees\n",
    "\n",
    "Use the the method `plot_tree()` from `sklearn.tree` module to print the tree on your notebook. Play with arguments like `feature_names`, `class_names`, `proportion`, `filled`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you think happened? Did you expect the resulting tree to have that size?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the `mlxtend.plotting` module, plot the decision boundaries for the Tree classification algorithm.\n",
    "\n",
    "Use `!pip install mlxtend --user` to install the `mlxtend` package\n",
    "\n",
    "\n",
    "_hint: you have to convert the dataframes to np.array before plotting in this package_\n",
    "\n",
    "Note: Include the labels on the plot using: \n",
    "\n",
    "`plt.xlabel(x_test.columns[0])`\n",
    "\n",
    "`plt.ylabel(x_test.columns[1]);`\n",
    "\n",
    "where x_test is your dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should have observed a high granularity of lines cutting the drawing. What do you think those represent? What exactly do they represent from a Tree algorithm? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T02:07:33.788598Z",
     "start_time": "2020-04-27T02:07:33.785606Z"
    }
   },
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform the same operation (i.e., use the `mlxtend.plotting` module to plot the decision boundary) for the Logistic Regression model you've created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What differences do you observe from them? The variable Age is important for the logistic regression? For different values of Age, how is the decision boundary affected? Why do you think that happens? Try to remember the `titanic-exploration` lab to recall how was Age correlated with the variable `Survived` and how we've managed to see some importance there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T02:09:52.107390Z",
     "start_time": "2020-04-27T02:09:52.104398Z"
    }
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fixing the Decision Tree algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you observed, an overfit occurred when using the default values of the DecisionTreeClassifier. This happens because, by default, the Decision Tree is so complex that it manages to memorize the whole dataset despite the granularity necessary to do that. It just keeps creating splits until each observation is memorized. \n",
    "\n",
    "In this sense, by default, the Decision Tree algorithm is **too complex**. We will solve this problem by making the tree a bit less complex. We'll change the parameter called `max_depth` for the DecisionTreeClassifier().\n",
    "\n",
    "Try to find a good value for `max_depth` that helps getting closer results within `train` and `test` scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T02:18:13.041188Z",
     "start_time": "2020-04-27T02:18:13.038196Z"
    }
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the resulting tree and deicision boundary. \n",
    "\n",
    "After choosing a good value for `max_depth`, i.e., a value that manages to get a good balance within performance and generalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T02:18:13.365525Z",
     "start_time": "2020-04-27T02:18:13.362533Z"
    }
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question:\n",
    "\n",
    "- Can you identify which one was the most important feature on this decision tree model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T02:19:56.862377Z",
     "start_time": "2020-04-27T02:19:56.859386Z"
    }
   },
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finally, use more variables\n",
    "\n",
    "Try to obtain a good score for your problem. Use more variables if you wish. You can plot the tree to understand the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T02:19:59.823541Z",
     "start_time": "2020-04-27T02:19:59.820522Z"
    }
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
