{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X3YSDiy0Up_C"
   },
   "source": [
    "# Evaluation: Precision & Recall\n",
    "## Using the evaluation metrics we have learned, we are going to compare how well some different types of classifiers perform on different evaluation metrics\n",
    "### We are going to use a dataset of written numbers which we can import from sklearn. Run the code below to do so. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T14:59:21.985593Z",
     "start_time": "2020-10-01T14:59:01.855307Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "fnUelxEmUp_D"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784')\n",
    "\n",
    "X, y = mnist['data'], mnist['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IMgKR4YhUp_G"
   },
   "source": [
    "### Now take a look at the shapes of the X and y matricies \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T14:59:21.990580Z",
     "start_time": "2020-10-01T14:59:21.986590Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "prseFXcoUp_H"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes\n",
      "X: (70000, 784)\n",
      "y: (70000,)\n"
     ]
    }
   ],
   "source": [
    "print(f'Shapes\\nX: {X.shape}\\ny: {y.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XRz_ivu3Up_J"
   },
   "source": [
    "### Now, let's pick one entry and see what number is written. Use indexing to pick the 36000th digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T14:59:22.005576Z",
     "start_time": "2020-10-01T14:59:21.992575Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "hIilw19uUp_J"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   4., 149.,\n",
       "       255., 184.,  12.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,  11., 133., 212., 253., 253., 253., 102.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0., 162., 236., 253., 253.,\n",
       "       253., 253., 253.,  55.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "        35., 196., 253., 253., 253., 253., 253., 253., 239.,  18.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,  89., 249., 253., 253., 253., 185.,\n",
       "       253., 253., 177.,  24.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 129.,\n",
       "       247., 253., 253., 165., 150., 205., 253., 139.,   3.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,  89., 247., 253., 240., 131.,  85., 221.,\n",
       "       253., 253.,  84.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   4., 187.,\n",
       "       253., 253., 236., 139., 252., 253., 253., 253.,  84.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,  21., 253., 253., 253., 253., 253., 253.,\n",
       "       253., 253., 248.,  53.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  99.,\n",
       "       253., 253., 253., 253., 253., 214., 253., 253., 179.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   4., 186., 251., 253., 249., 172.,\n",
       "       133., 253., 253., 137.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,  49.,  94.,   6.,   0., 212., 253., 253.,  39.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "       126., 253., 253., 197.,   6.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,  27., 234., 253., 253.,  94.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "       100., 253., 253., 239.,  11.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,  61., 249., 253., 253.,  79.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   5.,\n",
       "       109., 253., 253., 193.,   4.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,  66., 253., 253., 253.,  30.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "       147., 253., 253., 182.,   2.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,  99., 248., 253., 222.,  13.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check one entry\n",
    "X[36000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "90UIitfWUp_L"
   },
   "source": [
    "### You can use the .reshape(28,28) function and plt.imshow() function with the parameters cmap = matplotlib.cm.binary, interpolation=\"nearest\" to make a plot of the number. Be sure to import matplotlib!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T14:59:22.128641Z",
     "start_time": "2020-10-01T14:59:22.007537Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "euR2jMOEUp_L"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the image\n",
    "plt.imshow(X[36000].reshape(28, 28), cmap=\"binary\", interpolation=\"nearest\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lg12cNV4Up_O"
   },
   "source": [
    "### Use indexing to see if what the plot shows matches with the outcome of the 36000th index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T14:59:22.132605Z",
     "start_time": "2020-10-01T14:59:22.129589Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "IIrGU5pEUp_O"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[36000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "froaQc03Up_Q"
   },
   "source": [
    "### Now lets break into a test train split to run a classification. Instead of using sklearn, use indexing to select the first 60000 entries for the training, and the rest for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T14:59:22.138591Z",
     "start_time": "2020-10-01T14:59:22.133577Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "VrOasZSCUp_Q"
   },
   "outputs": [],
   "source": [
    "# Holdout\n",
    "X_train = X[:60000]\n",
    "X_test = X[60000:]\n",
    "\n",
    "y_train = y[:60000]\n",
    "y_test = y[60000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sdyH3KfzUp_T"
   },
   "source": [
    "### We are going to make a two-class classifier, so lets restrict to just one number, for example 5s. Do this by defining a new y training and y testing sets for just the number 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T14:59:22.144581Z",
     "start_time": "2020-10-01T14:59:22.139570Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "O23sEDJjUp_T"
   },
   "outputs": [],
   "source": [
    "y_train5 = y_train == '5'\n",
    "y_test5 = y_test == '5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X6vQQALZUp_V"
   },
   "source": [
    "### Lets train a logistic regression to predict if a number is a 5 or not (remember to use the 'just 5s' y training set!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T14:59:22.191472Z",
     "start_time": "2020-10-01T14:59:22.146577Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "KlPavPMzUp_V"
   },
   "outputs": [],
   "source": [
    "# Import library\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T15:01:31.844764Z",
     "start_time": "2020-10-01T14:59:22.192427Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\gabsn\\envs\\ds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=2000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instance the model\n",
    "lr = LogisticRegression(max_iter=2000)\n",
    "\n",
    "# Train the model\n",
    "lr.fit(X=X_train, y=y_train5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jmXXgi5TUp_X"
   },
   "source": [
    "### Does the classifier predict correctly the 36000th digit we picked before?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T15:01:31.850747Z",
     "start_time": "2020-10-01T15:01:31.845762Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "8MlPuH2SUp_Y"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the prediction for the 36000th digit\n",
    "lr.predict(X[[36000]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ALx4JWkFUp_a"
   },
   "source": [
    "### To make some comparisons, we are going to make a very dumb classifier, that never predicts 5s. Build the classifier with the code below, and call it using: never_5_clf = Never5Classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T15:01:31.856731Z",
     "start_time": "2020-10-01T15:01:31.851745Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "7X7WdYMtUp_b"
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "class Never5Classifier(BaseEstimator):\n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    def predict(self, X):\n",
    "        return np.zeros((len(X), 1), dtype=bool)\n",
    "\n",
    "never_5_clf = Never5Classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6b5bZIcXUp_d"
   },
   "source": [
    "### Now lets fit and predict on the testing set using our never 5 Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T15:01:31.861718Z",
     "start_time": "2020-10-01T15:01:31.857729Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "YAP7A9LlUp_e"
   },
   "outputs": [],
   "source": [
    "# Train the \"model\"\n",
    "never_5_clf.fit(X=X_train, y=y_train5)\n",
    "\n",
    "# Prediction\n",
    "y_pred_never_5 = never_5_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VrYZYL3aUp_g"
   },
   "source": [
    "### Let's compare this to the Logistic Regression. Examine the confusion matrix, precision, recall, and f1_scores for each. What is the probability cutoff you are using to decide the classes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T15:01:31.866706Z",
     "start_time": "2020-10-01T15:01:31.862715Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "g9aPqBXOUp_g"
   },
   "outputs": [],
   "source": [
    "# Import the library\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T15:01:31.892636Z",
     "start_time": "2020-10-01T15:01:31.868703Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predict using the Logistic Regression\n",
    "y_pred_5 = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T15:12:02.332435Z",
     "start_time": "2020-10-01T15:12:02.299498Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "Logistic Regression\n",
      "[[9027   81]\n",
      " [ 146  746]]\n",
      "\n",
      "Classifier\n",
      "[[9108    0]\n",
      " [ 892    0]]\n",
      "\n",
      "PRECISION\n",
      "Logistic Regression: 0.9020556227327691\n",
      "Classifier: 0.0\n",
      "\n",
      "RECALL\n",
      "Logistic Regression: 0.8363228699551569\n",
      "Classifier: 0.0\n",
      "\n",
      "F1 SCORE\n",
      "Logistic Regression: 0.8679464805119256\n",
      "Classifier: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "print('CONFUSION MATRIX')\n",
    "\n",
    "## Logistic Regression\n",
    "print(f'Logistic Regression\\n{confusion_matrix(y_true=y_test5, y_pred=y_pred_5)}')\n",
    "\n",
    "## Classifier\n",
    "print(f'\\nClassifier\\n{confusion_matrix(y_true=y_test5, y_pred=y_pred_never_5)}')\n",
    "\n",
    "# Precision\n",
    "print('\\nPRECISION')\n",
    "\n",
    "## Logistic Regression\n",
    "print(f'Logistic Regression: {precision_score(y_true=y_test5, y_pred=y_pred_5, zero_division=0)}')\n",
    "\n",
    "## Classifier\n",
    "print(f'Classifier: {precision_score(y_true=y_test5, y_pred=y_pred_never_5, zero_division=0)}')\n",
    "\n",
    "# Recall\n",
    "print('\\nRECALL')\n",
    "\n",
    "## Logistic Regression\n",
    "print(f'Logistic Regression: {recall_score(y_true=y_test5, y_pred=y_pred_5)}')\n",
    "\n",
    "## Classifier\n",
    "print(f'Classifier: {recall_score(y_true=y_test5, y_pred=y_pred_never_5)}')\n",
    "\n",
    "# F1 Score\n",
    "print('\\nF1 SCORE')\n",
    "\n",
    "## Logistic Regression\n",
    "print(f'Logistic Regression: {f1_score(y_true=y_test5, y_pred=y_pred_5)}')\n",
    "\n",
    "## Classifier\n",
    "print(f'Classifier: {f1_score(y_true=y_test5, y_pred=y_pred_never_5)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lvbi-m47Up_i"
   },
   "source": [
    "### What are the differences you see? Without knowing what each model is, what can these metrics tell you about how well each works?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T15:07:31.550699Z",
     "start_time": "2020-10-01T15:07:31.547716Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "t4JycFxNUp_i"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The Linear Regression model (first model) is better than the Classifier (second model). The first model coudl predict that\n",
      "there are 827 number 5, 746 being correctly predicted, while the second one predicted that there was no number 5 on\n",
      "the dataset. The Linear Regression model predicted correctly 9773 times out of the 10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'''\n",
    "The Linear Regression model (first model) is better than the Classifier (second model). The first model coudl predict that\n",
    "there are {81 + 746} number 5, 746 being correctly predicted, while the second one predicted that there was no number 5 on\n",
    "the dataset.\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "szmx0qxBUp_k"
   },
   "source": [
    "### Now let's examine the roc_curve for each. Use the roc_curve method from sklearn.metrics to help plot the curve for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T15:16:31.863456Z",
     "start_time": "2020-10-01T15:16:31.859467Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import the library\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, plot_roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T15:22:41.473991Z",
     "start_time": "2020-10-01T15:22:41.445092Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "0ObckzQRUp_k"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.09793588e-04,\n",
       "        1.09793588e-04, 2.19587176e-04, 2.19587176e-04, 3.29380764e-04,\n",
       "        3.29380764e-04, 4.39174352e-04, 4.39174352e-04, 5.48967940e-04,\n",
       "        5.48967940e-04, 6.58761528e-04, 6.58761528e-04, 7.68555116e-04,\n",
       "        7.68555116e-04, 9.88142292e-04, 9.88142292e-04, 1.09793588e-03,\n",
       "        1.09793588e-03, 1.20772947e-03, 1.20772947e-03, 1.31752306e-03,\n",
       "        1.31752306e-03, 1.42731664e-03, 1.42731664e-03, 1.53711023e-03,\n",
       "        1.53711023e-03, 1.64690382e-03, 1.64690382e-03, 1.75669741e-03,\n",
       "        1.75669741e-03, 1.86649100e-03, 1.86649100e-03, 1.97628458e-03,\n",
       "        1.97628458e-03, 2.08607817e-03, 2.08607817e-03, 2.19587176e-03,\n",
       "        2.19587176e-03, 2.30566535e-03, 2.30566535e-03, 2.41545894e-03,\n",
       "        2.41545894e-03, 2.52525253e-03, 2.52525253e-03, 2.63504611e-03,\n",
       "        2.63504611e-03, 2.85463329e-03, 2.85463329e-03, 2.96442688e-03,\n",
       "        2.96442688e-03, 3.07422047e-03, 3.07422047e-03, 3.18401405e-03,\n",
       "        3.18401405e-03, 3.29380764e-03, 3.29380764e-03, 3.40360123e-03,\n",
       "        3.40360123e-03, 3.51339482e-03, 3.51339482e-03, 3.62318841e-03,\n",
       "        3.62318841e-03, 3.73298199e-03, 3.73298199e-03, 3.84277558e-03,\n",
       "        3.84277558e-03, 3.95256917e-03, 3.95256917e-03, 4.06236276e-03,\n",
       "        4.06236276e-03, 4.17215635e-03, 4.17215635e-03, 4.28194993e-03,\n",
       "        4.28194993e-03, 4.39174352e-03, 4.39174352e-03, 4.50153711e-03,\n",
       "        4.50153711e-03, 4.61133070e-03, 4.61133070e-03, 4.72112429e-03,\n",
       "        4.72112429e-03, 4.83091787e-03, 4.83091787e-03, 4.94071146e-03,\n",
       "        4.94071146e-03, 5.37988581e-03, 5.37988581e-03, 5.48967940e-03,\n",
       "        5.48967940e-03, 5.59947299e-03, 5.59947299e-03, 5.70926658e-03,\n",
       "        5.70926658e-03, 5.81906017e-03, 5.81906017e-03, 5.92885375e-03,\n",
       "        5.92885375e-03, 6.03864734e-03, 6.03864734e-03, 6.36802811e-03,\n",
       "        6.36802811e-03, 6.47782170e-03, 6.47782170e-03, 6.69740887e-03,\n",
       "        6.69740887e-03, 6.80720246e-03, 6.80720246e-03, 7.02678964e-03,\n",
       "        7.02678964e-03, 7.13658322e-03, 7.13658322e-03, 7.35617040e-03,\n",
       "        7.35617040e-03, 7.46596399e-03, 7.46596399e-03, 7.68555116e-03,\n",
       "        7.68555116e-03, 8.01493193e-03, 8.01493193e-03, 8.12472552e-03,\n",
       "        8.12472552e-03, 8.23451910e-03, 8.23451910e-03, 8.45410628e-03,\n",
       "        8.45410628e-03, 8.67369346e-03, 8.67369346e-03, 8.89328063e-03,\n",
       "        8.89328063e-03, 9.11286781e-03, 9.11286781e-03, 9.66183575e-03,\n",
       "        9.66183575e-03, 9.99121651e-03, 9.99121651e-03, 1.04303909e-02,\n",
       "        1.04303909e-02, 1.05401845e-02, 1.05401845e-02, 1.06499780e-02,\n",
       "        1.06499780e-02, 1.09793588e-02, 1.09793588e-02, 1.17479139e-02,\n",
       "        1.17479139e-02, 1.18577075e-02, 1.18577075e-02, 1.19675011e-02,\n",
       "        1.19675011e-02, 1.20772947e-02, 1.20772947e-02, 1.22968819e-02,\n",
       "        1.22968819e-02, 1.24066755e-02, 1.24066755e-02, 1.27360562e-02,\n",
       "        1.27360562e-02, 1.28458498e-02, 1.28458498e-02, 1.33948177e-02,\n",
       "        1.33948177e-02, 1.47123408e-02, 1.47123408e-02, 1.49319280e-02,\n",
       "        1.49319280e-02, 1.50417216e-02, 1.50417216e-02, 1.63592446e-02,\n",
       "        1.63592446e-02, 1.67984190e-02, 1.67984190e-02, 1.71277997e-02,\n",
       "        1.71277997e-02, 1.73473869e-02, 1.73473869e-02, 1.75669741e-02,\n",
       "        1.75669741e-02, 1.78963549e-02, 1.78963549e-02, 1.80061484e-02,\n",
       "        1.80061484e-02, 1.88844971e-02, 1.88844971e-02, 2.04216074e-02,\n",
       "        2.04216074e-02, 2.05314010e-02, 2.05314010e-02, 2.07509881e-02,\n",
       "        2.07509881e-02, 2.14097497e-02, 2.14097497e-02, 2.16293368e-02,\n",
       "        2.16293368e-02, 2.19587176e-02, 2.19587176e-02, 2.31664471e-02,\n",
       "        2.31664471e-02, 2.44839701e-02, 2.44839701e-02, 2.55819060e-02,\n",
       "        2.55819060e-02, 2.59112868e-02, 2.59112868e-02, 2.63504611e-02,\n",
       "        2.63504611e-02, 2.65700483e-02, 2.65700483e-02, 3.00834431e-02,\n",
       "        3.00834431e-02, 3.14009662e-02, 3.14009662e-02, 3.24989021e-02,\n",
       "        3.24989021e-02, 3.29380764e-02, 3.29380764e-02, 3.52437418e-02,\n",
       "        3.52437418e-02, 3.53535354e-02, 3.53535354e-02, 3.85375494e-02,\n",
       "        3.85375494e-02, 3.90865173e-02, 3.90865173e-02, 4.15019763e-02,\n",
       "        4.15019763e-02, 4.47957839e-02, 4.47957839e-02, 4.80895916e-02,\n",
       "        4.80895916e-02, 4.85287659e-02, 4.85287659e-02, 4.89679403e-02,\n",
       "        4.89679403e-02, 5.16029864e-02, 5.16029864e-02, 5.17127800e-02,\n",
       "        5.17127800e-02, 5.18225736e-02, 5.18225736e-02, 5.31400966e-02,\n",
       "        5.31400966e-02, 5.36890646e-02, 5.36890646e-02, 5.39086517e-02,\n",
       "        5.39086517e-02, 5.45674133e-02, 5.45674133e-02, 5.73122530e-02,\n",
       "        5.73122530e-02, 5.76416337e-02, 5.76416337e-02, 6.07158542e-02,\n",
       "        6.07158542e-02, 6.09354414e-02, 6.09354414e-02, 6.21431708e-02,\n",
       "        6.21431708e-02, 6.46684234e-02, 6.46684234e-02, 7.18050066e-02,\n",
       "        7.18050066e-02, 7.54281950e-02, 7.54281950e-02, 7.74044796e-02,\n",
       "        7.74044796e-02, 8.09178744e-02, 8.09178744e-02, 8.14668423e-02,\n",
       "        8.14668423e-02, 8.31137462e-02, 8.31137462e-02, 8.33333333e-02,\n",
       "        8.33333333e-02, 8.43214756e-02, 8.43214756e-02, 8.98111550e-02,\n",
       "        8.98111550e-02, 9.01405358e-02, 9.01405358e-02, 9.44224857e-02,\n",
       "        9.44224857e-02, 9.87044357e-02, 9.87044357e-02, 9.92534036e-02,\n",
       "        9.92534036e-02, 1.00021959e-01, 1.00021959e-01, 1.04303909e-01,\n",
       "        1.04303909e-01, 1.08805446e-01, 1.08805446e-01, 1.11220905e-01,\n",
       "        1.11220905e-01, 1.15393061e-01, 1.15393061e-01, 1.24505929e-01,\n",
       "        1.24505929e-01, 1.32850242e-01, 1.32850242e-01, 1.38998682e-01,\n",
       "        1.38998682e-01, 1.41523935e-01, 1.41523935e-01, 1.43939394e-01,\n",
       "        1.43939394e-01, 1.44049188e-01, 1.44049188e-01, 1.46135266e-01,\n",
       "        1.46135266e-01, 1.54259991e-01, 1.54259991e-01, 1.57773386e-01,\n",
       "        1.57773386e-01, 1.59420290e-01, 1.59420290e-01, 1.68752745e-01,\n",
       "        1.68752745e-01, 2.03227931e-01, 2.03227931e-01, 2.19367589e-01,\n",
       "        2.19367589e-01, 2.39459816e-01, 2.39459816e-01, 2.56368028e-01,\n",
       "        2.56368028e-01, 2.70531401e-01, 2.70531401e-01, 2.82059728e-01,\n",
       "        2.82059728e-01, 2.83047870e-01, 2.83047870e-01, 2.86451471e-01,\n",
       "        2.86451471e-01, 2.92270531e-01, 2.92270531e-01, 3.00505051e-01,\n",
       "        3.00505051e-01, 3.08849363e-01, 3.08849363e-01, 3.30368906e-01,\n",
       "        3.30368906e-01, 3.35199824e-01, 3.35199824e-01, 3.43214756e-01,\n",
       "        3.43214756e-01, 3.96903821e-01, 3.96903821e-01, 4.08322354e-01,\n",
       "        4.08322354e-01, 4.19301713e-01, 4.19301713e-01, 6.04413702e-01,\n",
       "        6.04413702e-01, 6.17259552e-01, 6.17259552e-01, 6.70180061e-01,\n",
       "        6.70180061e-01, 6.79183136e-01, 6.79183136e-01, 7.77997365e-01,\n",
       "        7.77997365e-01, 8.10166886e-01, 8.10166886e-01, 8.20816864e-01,\n",
       "        8.20816864e-01, 8.50021959e-01, 8.50021959e-01, 8.67588933e-01,\n",
       "        8.67588933e-01, 8.95805885e-01, 8.95805885e-01, 9.47738252e-01,\n",
       "        9.47738252e-01, 9.48726394e-01, 9.48726394e-01, 9.50922266e-01,\n",
       "        9.50922266e-01, 1.00000000e+00]),\n",
       " array([0.        , 0.00112108, 0.0426009 , 0.0426009 , 0.05829596,\n",
       "        0.05829596, 0.06278027, 0.06278027, 0.20627803, 0.20627803,\n",
       "        0.26793722, 0.26793722, 0.28251121, 0.28251121, 0.30269058,\n",
       "        0.30269058, 0.39461883, 0.39461883, 0.44730942, 0.44730942,\n",
       "        0.47197309, 0.47197309, 0.49215247, 0.49215247, 0.49327354,\n",
       "        0.49327354, 0.51121076, 0.51121076, 0.53363229, 0.53363229,\n",
       "        0.53699552, 0.53699552, 0.55044843, 0.55044843, 0.56053812,\n",
       "        0.56053812, 0.59753363, 0.59753363, 0.60538117, 0.60538117,\n",
       "        0.60874439, 0.60874439, 0.61434978, 0.61434978, 0.61659193,\n",
       "        0.61659193, 0.62668161, 0.62668161, 0.65358744, 0.65358744,\n",
       "        0.66591928, 0.66591928, 0.67600897, 0.67600897, 0.68161435,\n",
       "        0.68161435, 0.68609865, 0.68609865, 0.68946188, 0.68946188,\n",
       "        0.69058296, 0.69058296, 0.69282511, 0.69282511, 0.69618834,\n",
       "        0.69618834, 0.70179372, 0.70179372, 0.70403587, 0.70403587,\n",
       "        0.71412556, 0.71412556, 0.71524664, 0.71524664, 0.72982063,\n",
       "        0.72982063, 0.7309417 , 0.7309417 , 0.73430493, 0.73430493,\n",
       "        0.7544843 , 0.7544843 , 0.75672646, 0.75672646, 0.76008969,\n",
       "        0.76008969, 0.76121076, 0.76121076, 0.76345291, 0.76345291,\n",
       "        0.76681614, 0.76681614, 0.77578475, 0.77578475, 0.78139013,\n",
       "        0.78139013, 0.78475336, 0.78475336, 0.78587444, 0.78587444,\n",
       "        0.7926009 , 0.7926009 , 0.79820628, 0.79820628, 0.80044843,\n",
       "        0.80044843, 0.80156951, 0.80156951, 0.80269058, 0.80269058,\n",
       "        0.80381166, 0.80381166, 0.80493274, 0.80493274, 0.80829596,\n",
       "        0.80829596, 0.81278027, 0.81278027, 0.8161435 , 0.8161435 ,\n",
       "        0.81726457, 0.81726457, 0.82735426, 0.82735426, 0.82959641,\n",
       "        0.82959641, 0.83408072, 0.83408072, 0.83520179, 0.83520179,\n",
       "        0.83632287, 0.83632287, 0.83744395, 0.83744395, 0.83856502,\n",
       "        0.83856502, 0.8396861 , 0.8396861 , 0.84641256, 0.84641256,\n",
       "        0.84753363, 0.84753363, 0.85089686, 0.85089686, 0.85201794,\n",
       "        0.85201794, 0.85313901, 0.85313901, 0.85650224, 0.85650224,\n",
       "        0.85874439, 0.85874439, 0.85986547, 0.85986547, 0.86098655,\n",
       "        0.86098655, 0.8632287 , 0.8632287 , 0.86434978, 0.86434978,\n",
       "        0.86547085, 0.86547085, 0.86659193, 0.86659193, 0.867713  ,\n",
       "        0.867713  , 0.86883408, 0.86883408, 0.86995516, 0.86995516,\n",
       "        0.87219731, 0.87219731, 0.87331839, 0.87331839, 0.87443946,\n",
       "        0.87443946, 0.87556054, 0.87556054, 0.87668161, 0.87668161,\n",
       "        0.87780269, 0.87780269, 0.87892377, 0.87892377, 0.88004484,\n",
       "        0.88004484, 0.88116592, 0.88116592, 0.88340807, 0.88340807,\n",
       "        0.88452915, 0.88452915, 0.88565022, 0.88565022, 0.88789238,\n",
       "        0.88789238, 0.88901345, 0.88901345, 0.89013453, 0.89013453,\n",
       "        0.89237668, 0.89237668, 0.89461883, 0.89461883, 0.89573991,\n",
       "        0.89573991, 0.89686099, 0.89686099, 0.89798206, 0.89798206,\n",
       "        0.89910314, 0.89910314, 0.90134529, 0.90134529, 0.90246637,\n",
       "        0.90246637, 0.90358744, 0.90358744, 0.9058296 , 0.9058296 ,\n",
       "        0.90695067, 0.90695067, 0.90807175, 0.90807175, 0.90919283,\n",
       "        0.90919283, 0.9103139 , 0.9103139 , 0.91143498, 0.91143498,\n",
       "        0.91255605, 0.91255605, 0.91479821, 0.91479821, 0.91591928,\n",
       "        0.91591928, 0.91704036, 0.91704036, 0.91816143, 0.91816143,\n",
       "        0.92040359, 0.92040359, 0.92152466, 0.92152466, 0.92264574,\n",
       "        0.92264574, 0.92376682, 0.92376682, 0.92488789, 0.92488789,\n",
       "        0.92600897, 0.92600897, 0.92713004, 0.92713004, 0.92825112,\n",
       "        0.92825112, 0.9293722 , 0.9293722 , 0.93049327, 0.93049327,\n",
       "        0.93161435, 0.93161435, 0.93273543, 0.93273543, 0.9338565 ,\n",
       "        0.9338565 , 0.93497758, 0.93497758, 0.93609865, 0.93609865,\n",
       "        0.93834081, 0.93834081, 0.93946188, 0.93946188, 0.94058296,\n",
       "        0.94058296, 0.94170404, 0.94170404, 0.94282511, 0.94282511,\n",
       "        0.94394619, 0.94394619, 0.94506726, 0.94506726, 0.94618834,\n",
       "        0.94618834, 0.94730942, 0.94730942, 0.94843049, 0.94843049,\n",
       "        0.94955157, 0.94955157, 0.95067265, 0.95067265, 0.95179372,\n",
       "        0.95179372, 0.9529148 , 0.9529148 , 0.95403587, 0.95403587,\n",
       "        0.95515695, 0.95515695, 0.95627803, 0.95627803, 0.9573991 ,\n",
       "        0.9573991 , 0.95852018, 0.95852018, 0.95964126, 0.95964126,\n",
       "        0.96076233, 0.96076233, 0.96188341, 0.96188341, 0.96300448,\n",
       "        0.96300448, 0.96412556, 0.96412556, 0.96524664, 0.96524664,\n",
       "        0.96636771, 0.96636771, 0.96748879, 0.96748879, 0.96860987,\n",
       "        0.96860987, 0.96973094, 0.96973094, 0.97085202, 0.97085202,\n",
       "        0.97197309, 0.97197309, 0.97309417, 0.97309417, 0.97421525,\n",
       "        0.97421525, 0.97533632, 0.97533632, 0.9764574 , 0.9764574 ,\n",
       "        0.97757848, 0.97757848, 0.97869955, 0.97869955, 0.97982063,\n",
       "        0.97982063, 0.9809417 , 0.9809417 , 0.98206278, 0.98206278,\n",
       "        0.98318386, 0.98318386, 0.98430493, 0.98430493, 0.98542601,\n",
       "        0.98542601, 0.98654709, 0.98654709, 0.98766816, 0.98766816,\n",
       "        0.98878924, 0.98878924, 0.98991031, 0.98991031, 0.99103139,\n",
       "        0.99103139, 0.99215247, 0.99215247, 0.99327354, 0.99327354,\n",
       "        0.99439462, 0.99439462, 0.9955157 , 0.9955157 , 0.99663677,\n",
       "        0.99663677, 0.99775785, 0.99775785, 0.99887892, 0.99887892,\n",
       "        1.        , 1.        ]),\n",
       " array([ 9.99999939e-01, -6.09965261e-08, -2.26350172e-04, -2.33282085e-04,\n",
       "        -4.39764152e-04, -4.64696200e-04, -4.89864581e-04, -5.36464833e-04,\n",
       "        -5.16624430e-03, -5.17104282e-03, -9.46714043e-03, -9.51490111e-03,\n",
       "        -1.11006074e-02, -1.12051450e-02, -1.36822023e-02, -1.37774112e-02,\n",
       "        -2.85240073e-02, -2.90374282e-02, -4.20301816e-02, -4.22899808e-02,\n",
       "        -5.01676596e-02, -5.03851703e-02, -5.85219069e-02, -5.92841341e-02,\n",
       "        -5.95775158e-02, -6.15206511e-02, -7.11160331e-02, -7.24765421e-02,\n",
       "        -8.39952120e-02, -8.59839114e-02, -8.89407292e-02, -8.94627016e-02,\n",
       "        -9.64777078e-02, -9.66580849e-02, -1.03406715e-01, -1.03914043e-01,\n",
       "        -1.29181790e-01, -1.29590085e-01, -1.33561854e-01, -1.34640990e-01,\n",
       "        -1.38124592e-01, -1.38769430e-01, -1.43590074e-01, -1.43888814e-01,\n",
       "        -1.44758474e-01, -1.45107609e-01, -1.54435519e-01, -1.55185565e-01,\n",
       "        -1.81351269e-01, -1.84840072e-01, -1.97370775e-01, -2.00152075e-01,\n",
       "        -2.08652072e-01, -2.10371907e-01, -2.15886086e-01, -2.17068170e-01,\n",
       "        -2.25878398e-01, -2.26270504e-01, -2.30623015e-01, -2.33686132e-01,\n",
       "        -2.36054910e-01, -2.37464231e-01, -2.42037404e-01, -2.42074402e-01,\n",
       "        -2.47419036e-01, -2.50613868e-01, -2.60564519e-01, -2.62773171e-01,\n",
       "        -2.65711852e-01, -2.66409854e-01, -2.74791973e-01, -2.75362830e-01,\n",
       "        -2.77889046e-01, -2.78701686e-01, -3.05687337e-01, -3.09481717e-01,\n",
       "        -3.14723223e-01, -3.14851482e-01, -3.20236465e-01, -3.22318181e-01,\n",
       "        -3.67514613e-01, -3.68988734e-01, -3.76081061e-01, -3.79718705e-01,\n",
       "        -3.84673026e-01, -3.85079301e-01, -3.85724818e-01, -3.87634191e-01,\n",
       "        -3.94493610e-01, -3.97542989e-01, -4.09876126e-01, -4.11409455e-01,\n",
       "        -4.34608240e-01, -4.36183112e-01, -4.48477810e-01, -4.58440963e-01,\n",
       "        -4.71266078e-01, -4.72502345e-01, -4.74089128e-01, -4.75341138e-01,\n",
       "        -4.85027260e-01, -4.89837438e-01, -4.95528084e-01, -5.00779709e-01,\n",
       "        -5.14638730e-01, -5.14705324e-01, -5.18065741e-01, -5.23442557e-01,\n",
       "        -5.24585974e-01, -5.25189150e-01, -5.29428451e-01, -5.34401187e-01,\n",
       "        -5.38286514e-01, -5.39113185e-01, -5.55837068e-01, -5.56727201e-01,\n",
       "        -5.66318531e-01, -5.66594734e-01, -5.76821591e-01, -5.95022324e-01,\n",
       "        -6.03523428e-01, -6.07966832e-01, -6.42298481e-01, -6.44678925e-01,\n",
       "        -6.48294394e-01, -6.49262447e-01, -6.54826240e-01, -6.64313302e-01,\n",
       "        -6.67083614e-01, -6.78645461e-01, -6.85811471e-01, -6.92905625e-01,\n",
       "        -6.97507345e-01, -7.15796356e-01, -7.19459448e-01, -7.35080476e-01,\n",
       "        -7.35683854e-01, -7.75694288e-01, -7.89695613e-01, -7.94713575e-01,\n",
       "        -8.09370946e-01, -8.17651921e-01, -8.40153273e-01, -8.42443107e-01,\n",
       "        -8.47208710e-01, -8.66447795e-01, -8.70183361e-01, -8.91584562e-01,\n",
       "        -9.05006734e-01, -9.05631584e-01, -9.07669545e-01, -9.07828877e-01,\n",
       "        -9.09337822e-01, -9.10219363e-01, -9.10809462e-01, -9.12009266e-01,\n",
       "        -9.18941514e-01, -9.19080085e-01, -9.25513961e-01, -9.33708033e-01,\n",
       "        -9.38068667e-01, -9.40206970e-01, -9.40287554e-01, -9.70495340e-01,\n",
       "        -9.72512842e-01, -1.02854763e+00, -1.03065535e+00, -1.03212594e+00,\n",
       "        -1.03550508e+00, -1.03562379e+00, -1.03903231e+00, -1.08694877e+00,\n",
       "        -1.08864559e+00, -1.10804203e+00, -1.10971189e+00, -1.12805478e+00,\n",
       "        -1.12822359e+00, -1.13928056e+00, -1.13948439e+00, -1.15227272e+00,\n",
       "        -1.15662804e+00, -1.18067761e+00, -1.18846306e+00, -1.19595981e+00,\n",
       "        -1.19904911e+00, -1.21879298e+00, -1.23328366e+00, -1.28180828e+00,\n",
       "        -1.29139283e+00, -1.29537074e+00, -1.29863013e+00, -1.30471799e+00,\n",
       "        -1.30501991e+00, -1.31061206e+00, -1.31385734e+00, -1.31928620e+00,\n",
       "        -1.32443556e+00, -1.34593049e+00, -1.34899220e+00, -1.38724188e+00,\n",
       "        -1.39522163e+00, -1.42923412e+00, -1.43398335e+00, -1.49905842e+00,\n",
       "        -1.50485931e+00, -1.51576147e+00, -1.51634557e+00, -1.54066318e+00,\n",
       "        -1.54407125e+00, -1.54983996e+00, -1.55339601e+00, -1.67620269e+00,\n",
       "        -1.68171199e+00, -1.72058242e+00, -1.72325692e+00, -1.75414994e+00,\n",
       "        -1.75908208e+00, -1.77269044e+00, -1.77494394e+00, -1.82343430e+00,\n",
       "        -1.82623335e+00, -1.83066205e+00, -1.83105943e+00, -1.91024245e+00,\n",
       "        -1.91649195e+00, -1.92426380e+00, -1.92505251e+00, -1.99165985e+00,\n",
       "        -1.99279617e+00, -2.09719096e+00, -2.09923533e+00, -2.19687442e+00,\n",
       "        -2.20409929e+00, -2.21180053e+00, -2.21205022e+00, -2.22075380e+00,\n",
       "        -2.22199714e+00, -2.28180781e+00, -2.28291593e+00, -2.28312453e+00,\n",
       "        -2.28456786e+00, -2.28557051e+00, -2.28657513e+00, -2.31782482e+00,\n",
       "        -2.31953715e+00, -2.32994832e+00, -2.33342598e+00, -2.33655261e+00,\n",
       "        -2.33667783e+00, -2.35199692e+00, -2.35634087e+00, -2.41699883e+00,\n",
       "        -2.41809127e+00, -2.42313535e+00, -2.42453678e+00, -2.47680246e+00,\n",
       "        -2.47755133e+00, -2.48885232e+00, -2.49234447e+00, -2.51490090e+00,\n",
       "        -2.51740913e+00, -2.56324028e+00, -2.56453251e+00, -2.69393853e+00,\n",
       "        -2.69527004e+00, -2.75032547e+00, -2.75259627e+00, -2.80384442e+00,\n",
       "        -2.80670754e+00, -2.86662576e+00, -2.87409482e+00, -2.88256737e+00,\n",
       "        -2.88466142e+00, -2.90085454e+00, -2.90088136e+00, -2.90599155e+00,\n",
       "        -2.90701405e+00, -2.92159743e+00, -2.92303979e+00, -3.01791494e+00,\n",
       "        -3.01798476e+00, -3.02150146e+00, -3.02501436e+00, -3.09303370e+00,\n",
       "        -3.09420384e+00, -3.17247517e+00, -3.17260860e+00, -3.17852817e+00,\n",
       "        -3.18312432e+00, -3.19187778e+00, -3.19192922e+00, -3.27270805e+00,\n",
       "        -3.27354715e+00, -3.35191205e+00, -3.35248272e+00, -3.37753767e+00,\n",
       "        -3.37852948e+00, -3.43558380e+00, -3.43751185e+00, -3.55841030e+00,\n",
       "        -3.55927838e+00, -3.67471477e+00, -3.67650767e+00, -3.76749478e+00,\n",
       "        -3.76811440e+00, -3.79123119e+00, -3.79317692e+00, -3.82862409e+00,\n",
       "        -3.82867299e+00, -3.82900861e+00, -3.83004235e+00, -3.85243243e+00,\n",
       "        -3.85340536e+00, -3.96326028e+00, -3.96339936e+00, -4.02757231e+00,\n",
       "        -4.02815362e+00, -4.03963247e+00, -4.03964652e+00, -4.15106310e+00,\n",
       "        -4.15400621e+00, -4.53260379e+00, -4.54013465e+00, -4.68138789e+00,\n",
       "        -4.68173284e+00, -4.87259297e+00, -4.87465453e+00, -5.03878790e+00,\n",
       "        -5.03961153e+00, -5.17424761e+00, -5.17498212e+00, -5.28907996e+00,\n",
       "        -5.29107039e+00, -5.29880938e+00, -5.29904182e+00, -5.33076754e+00,\n",
       "        -5.33116154e+00, -5.38145537e+00, -5.38154691e+00, -5.46276819e+00,\n",
       "        -5.46455911e+00, -5.53702567e+00, -5.53883745e+00, -5.74905831e+00,\n",
       "        -5.74991984e+00, -5.79898685e+00, -5.80044672e+00, -5.87207505e+00,\n",
       "        -5.87468471e+00, -6.33578680e+00, -6.33687177e+00, -6.44814492e+00,\n",
       "        -6.44848923e+00, -6.54624002e+00, -6.54908246e+00, -8.52072937e+00,\n",
       "        -8.52356745e+00, -8.67513315e+00, -8.67544140e+00, -9.41504104e+00,\n",
       "        -9.41751756e+00, -9.54470806e+00, -9.54594887e+00, -1.14071190e+01,\n",
       "        -1.14078006e+01, -1.21942303e+01, -1.22041592e+01, -1.24987072e+01,\n",
       "        -1.24991211e+01, -1.34365166e+01, -1.34456047e+01, -1.41492221e+01,\n",
       "        -1.41557662e+01, -1.56066388e+01, -1.56068631e+01, -2.14917093e+01,\n",
       "        -2.15132916e+01, -2.16970764e+01, -2.17274892e+01, -2.21202490e+01,\n",
       "        -2.21516901e+01, -9.14743472e+01]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ROC Curve\n",
    "roc_curve(y_true=y_test5, y_score=lr.predict_log_proba(X_test)[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZPhGeQHuUp_m"
   },
   "source": [
    "### Now find the roc_auc_score for each. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vz4Gn4j_Up_o"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pUfStJ6lUp_p"
   },
   "source": [
    "### Using the yellowbrick library  plot the roc_auc_score curve for the logistic model . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VTytAzX7Up_q"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vda4i6JZUp_s"
   },
   "source": [
    "### What does this metric tell you? Which classifier works better with this metric in mind?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "94kkn4-hUp_s"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "main.ipynb",
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
